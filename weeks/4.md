# Monday

- [ ] Run indit with locally build image for class2 scorer
- [x] Review hanna soring
https://github.com/OncoImmunity/class2-scorer/pull/13#pullrequestreview-2488117167
- [x] review HLA coverage PR.
https://github.com/OncoImmunity/peptide_coverage/pull/7/files
I was doing some extra testing of this locally, and I think there is a micro bug here. Where this will exit after printing just one missing column even if there are multiple missing due to the `sys.exit(1)` indentation.
This lead me down a path of if we could leverage polars schema validation more here to validate the df schemas since you've already got the nice schema defined for each df. If you are interested @perllb I can open a PR with that?
- [ ] comment with simpler schema validation with polars
- [x] Review Erlend TF PR
- [x] Prepare a paragraph with example commands for uv in indit for discussion meeting

Curious to try out [[Snapshot testing]] for our code. Think reviewing
snapshot test changes could be very easy.

I got access to the [[Hetzner servers]] account today in Bitwarden.

- [ ] Make first code change for better intermediate output PR
[[2412-indit-intermediary-metrics]]

Fuck ruff is as appealing as uv almost. I think all the linting we do in indit could be done
with ruff. 
> Ruff can be used to replace Flake8 (plus dozens of plugins), Black, isort, pydocstyle, pyupgrade, autoflake, and more, all while executing tens or hundreds of times faster than any individual tool.

I want to bump ruff.
I want to replace xdoctest, isort and black with ruff.

All tests with pytest.
All linting with ruff.
All deps stuff with black.
In all our repos. Super fast linting. Fast installs.
Well formatted and consistent code.
Then dip our toes into snapshot testing, and get people proficient in that.
Then we can write code that is very easy to review, very quickly.
Then I can start writing better test for the model upgrade stuff so we can
plonk in new models witohut too much worry.


Will meet with [[Saverio Niccolini]] for a [[Saverio Intro meeting]].

Tomorrow we have the [[Infectious disease discussion meeting 13.09.24]]

# Tuesday
- Finish clean up intermediary files
    - Test workflow tests on cepi9
    - Run integration tests
        - verify that peptides_ap.csv is there and all others are gone.
- Reques review for intermediary files
- Review class2scorer by Hanna

- Start on adding columns to the all_predicitions output
    - Create jira issue for the normalized binding scores
    - Add normalized binding scores to all_predictions outupt

Maybe wait with adding scores from processing model?

Does cursor read csv and tsv files we have in lfs? Could that be the crash causer?
How do cursor and lfs mesh.

Requirements for [[indit]]
https://neconcoimmunity.atlassian.net/wiki/spaces/ID/pages/1180368945/INDIT+v1.x.x+Software+Requirements+Specifications+V01#Component:-class2-scorer-[WIP]

By having cli tools for each pipeline step we loose type hints, and python
type checker help.
I really wonder if it is the way to go.
You do get very clear module with input arguments and outputs.

[[uv in indit]] thinking about how to do the pip environment variable on the servers.
https://adamj.eu/tech/2019/03/20/how-i-provision-my-macbook-with-ansible/
Who to tag for review of using uv for indit?
Installing uv and settin the UV_PIP_EXTA_INDEX_URL on the servers
would mean it is very smooth for people to us indit.